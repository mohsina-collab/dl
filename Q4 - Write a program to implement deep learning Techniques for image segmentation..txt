Q4 - Write a program to implement deep learning Techniques for image segmentation.


import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

np.random.seed(42)

def create_toy_dataset(n_samples, img_size=64):
    X = np.zeros((n_samples, img_size, img_size, 1), dtype=np.float32)
    y = np.zeros((n_samples, img_size, img_size, 1), dtype=np.float32)
    
    for i in range(n_samples):
        img = np.random.random((img_size, img_size, 1)) * 0.5
        mask = np.zeros((img_size, img_size, 1))
        center = np.random.randint(20, 44, 2)
        radius = np.random.randint(10, 20)
        y_grid, x_grid = np.ogrid[:img_size, :img_size]
        mask_region = (x_grid - center[1])**2 + (y_grid - center[0])**2 <= radius**2
        mask[mask_region] = 1.0
        img[mask_region] += 0.5
        X[i] = img / np.max(img)
        y[i] = mask
    return X, y

X_train, y_train = create_toy_dataset(100)
X_test, y_test = create_toy_dataset(10)

def unet_model(input_shape=(64, 64, 1)):
    inputs = tf.keras.layers.Input(input_shape)
    c1 = tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same')(inputs)
    c1 = tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same')(c1)
    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)
    
    c2 = tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same')(p1)
    c2 = tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same')(c2)
    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)
    
    c3 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(p2)
    c3 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(c3)
    
    u4 = tf.keras.layers.Conv2DTranspose(32, 3, strides=(2, 2), padding='same')(c3)
    u4 = tf.keras.layers.Concatenate()([u4, c2])
    c4 = tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same')(u4)
    c4 = tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same')(c4)
    
    u5 = tf.keras.layers.Conv2DTranspose(16, 3, strides=(2, 2), padding='same')(c4)
    u5 = tf.keras.layers.Concatenate()([u5, c1])
    c5 = tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same')(u5)
    c5 = tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same')(c5)
    
    outputs = tf.keras.layers.Conv2D(1, 1, activation='sigmoid')(c5)
    return tf.keras.Model(inputs, outputs)

model = unet_model()
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), verbose=0)

plt.figure(figsize=(15, 5))
plt.subplot(1, 3, 1)
plt.imshow(X_test[0, :, :, 0], cmap='gray')
plt.title("Input Image")

plt.subplot(1, 3, 2)
plt.imshow(y_test[0, :, :, 0], cmap='gray')
plt.title("Ground Truth Mask")

pred = model.predict(X_test[:1])[0, :, :, 0]
plt.subplot(1, 3, 3)
plt.imshow(pred, cmap='gray')
plt.title("Predicted Mask")

plt.tight_layout()
plt.savefig("segmentation_result.png")

print("Segmentation Accuracy:", history.history['val_accuracy'][-1])